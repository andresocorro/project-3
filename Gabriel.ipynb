{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "# shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "\n",
    "# see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "# load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "# already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "# this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "# we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "# make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "# add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "# scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "# add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "# add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "# last `lookup_step` columns contains NaN in future column\n",
    "# get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "# drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "# get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "# for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "# this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "# add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "# construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "# convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "# split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "# shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "# split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "# get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "# retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "# remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "# remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "# first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "# last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "# hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "# add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 15\n",
    "# whether to scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# whether to shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# whether to split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# whether to use bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "# Amazon stock market\n",
    "ticker = \"AMZN\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the following folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "74/74 [==============================] - 29s 361ms/step - loss: 0.0045 - mean_absolute_error: 0.0438 - val_loss: 1.3347e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00013, saving model to results/2021-01-19_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - 31s 417ms/step - loss: 3.1516e-04 - mean_absolute_error: 0.0126 - val_loss: 1.5758e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00013\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - 33s 446ms/step - loss: 4.1227e-04 - mean_absolute_error: 0.0131 - val_loss: 1.6724e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00013\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - 34s 460ms/step - loss: 3.7556e-04 - mean_absolute_error: 0.0132 - val_loss: 1.7840e-04 - val_mean_absolute_error: 0.0088\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00013\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - 35s 479ms/step - loss: 4.8267e-04 - mean_absolute_error: 0.0153 - val_loss: 1.8093e-04 - val_mean_absolute_error: 0.0098\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.00013\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - 32s 434ms/step - loss: 3.7687e-04 - mean_absolute_error: 0.0138 - val_loss: 2.1726e-04 - val_mean_absolute_error: 0.0109\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.00013\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - 32s 430ms/step - loss: 3.6702e-04 - mean_absolute_error: 0.0134 - val_loss: 1.2165e-04 - val_mean_absolute_error: 0.0069\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.00013 to 0.00012, saving model to results/2021-01-19_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - 34s 460ms/step - loss: 3.1663e-04 - mean_absolute_error: 0.0122 - val_loss: 2.0917e-04 - val_mean_absolute_error: 0.0131\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.00012\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - 37s 497ms/step - loss: 3.5428e-04 - mean_absolute_error: 0.0131 - val_loss: 2.4394e-04 - val_mean_absolute_error: 0.0113\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.00012\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - 38s 510ms/step - loss: 4.5402e-04 - mean_absolute_error: 0.0163 - val_loss: 3.6702e-04 - val_mean_absolute_error: 0.0195\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.00012\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - 37s 502ms/step - loss: 3.8588e-04 - mean_absolute_error: 0.0143 - val_loss: 1.3527e-04 - val_mean_absolute_error: 0.0080\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.00012\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - 34s 457ms/step - loss: 3.1144e-04 - mean_absolute_error: 0.0134 - val_loss: 4.8464e-04 - val_mean_absolute_error: 0.0176\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.00012\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - 30s 412ms/step - loss: 4.4556e-04 - mean_absolute_error: 0.0150 - val_loss: 1.2131e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.00012 to 0.00012, saving model to results/2021-01-19_AMZN-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-15-layers-2-units-256.h5\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - 32s 429ms/step - loss: 2.9556e-04 - mean_absolute_error: 0.0116 - val_loss: 1.2866e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.00012\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - 31s 420ms/step - loss: 3.0509e-04 - mean_absolute_error: 0.0119 - val_loss: 1.7502e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.00012\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - 33s 442ms/step - loss: 4.2057e-04 - mean_absolute_error: 0.0141 - val_loss: 1.5739e-04 - val_mean_absolute_error: 0.0083\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.00012\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - 31s 413ms/step - loss: 3.4390e-04 - mean_absolute_error: 0.0131 - val_loss: 2.2011e-04 - val_mean_absolute_error: 0.0148\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.00012\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - 31s 426ms/step - loss: 3.3343e-04 - mean_absolute_error: 0.0141 - val_loss: 2.7952e-04 - val_mean_absolute_error: 0.0120\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.00012\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - 32s 429ms/step - loss: 2.9448e-04 - mean_absolute_error: 0.0124 - val_loss: 1.3628e-04 - val_mean_absolute_error: 0.0070\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.00012\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - 31s 414ms/step - loss: 2.5539e-04 - mean_absolute_error: 0.0114 - val_loss: 1.4526e-04 - val_mean_absolute_error: 0.0081\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.00012\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to operator (<ipython-input-32-10d2db8c4a5d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-32-10d2db8c4a5d>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorflow --logdir=\"logs\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to operator\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "  \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "# if the predicted future price is lower than the current price,\n",
    "# then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "# perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "# add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "# add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "# sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "# add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "# add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process with Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 15 days is 3115.73$\n",
      "huber_loss loss: 0.00012130630784668028\n",
      "Mean Absolute Error: 26.265136467176443\n",
      "Accuracy score: 0.5852417302798982\n",
      "Total buy profit: 9445.955698728561\n",
      "Total sell profit: -4688.928969860077\n",
      "Total profit: 4757.0267288684845\n",
      "Profit per trade: 4.034797904044516\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   open         high          low        close     adjclose  \\\n",
      "2020-10-27  3224.939941  3291.659912  3211.300049  3286.330078  3286.330078   \n",
      "2020-10-28  3249.300049  3264.020020  3162.469971  3162.780029  3162.780029   \n",
      "2020-11-03  3018.530029  3074.899902  2980.979980  3048.409912  3048.409912   \n",
      "2020-11-10  3095.020020  3114.000000  3019.479980  3035.020020  3035.020020   \n",
      "2020-11-17  3183.540039  3189.250000  3135.260010  3135.659912  3135.659912   \n",
      "2020-11-20  3117.020020  3132.889893  3098.050049  3099.399902  3099.399902   \n",
      "2020-11-23  3116.699951  3139.750000  3065.459961  3098.389893  3098.389893   \n",
      "2020-12-01  3188.500000  3248.949951  3157.179932  3220.080078  3220.080078   \n",
      "2020-12-08  3158.899902  3184.129883  3120.020020  3177.290039  3177.290039   \n",
      "2020-12-17  3250.000000  3263.510010  3221.000000  3236.080078  3236.080078   \n",
      "\n",
      "             volume ticker  adjclose_15  true_adjclose_15  buy_profit  \\\n",
      "2020-10-27  4291000   AMZN  3185.655029       3135.659912    0.000000   \n",
      "2020-10-28  5588300   AMZN  3184.023926       3105.459961    0.000000   \n",
      "2020-11-03  4897900   AMZN  3100.163818       3118.060059   51.753906   \n",
      "2020-11-10  6591000   AMZN  3155.381592       3203.530029  120.361572   \n",
      "2020-11-17  3444700   AMZN  3107.172852       3104.199951    0.000000   \n",
      "2020-11-20  3374400   AMZN  3097.170410       3156.969971   -2.229492   \n",
      "2020-11-23  4708900   AMZN  3092.696045       3165.120117   -5.693848   \n",
      "2020-12-01  4544400   AMZN  3134.153809       3206.520020    0.000000   \n",
      "2020-12-08  3286300   AMZN  3148.782959       3285.850098  -28.507080   \n",
      "2020-12-17  3474300   AMZN  3139.521729       3114.209961    0.000000   \n",
      "\n",
      "            sell_profit  \n",
      "2020-10-27   100.675049  \n",
      "2020-10-28   -21.243896  \n",
      "2020-11-03     0.000000  \n",
      "2020-11-10     0.000000  \n",
      "2020-11-17    28.487061  \n",
      "2020-11-20     0.000000  \n",
      "2020-11-23     0.000000  \n",
      "2020-12-01    85.926270  \n",
      "2020-12-08     0.000000  \n",
      "2020-12-17    96.558350  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

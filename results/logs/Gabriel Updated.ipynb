{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    \n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "        # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.101087</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095813</td>\n",
       "      <td>175884800.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088780</td>\n",
       "      <td>105728000.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090978</td>\n",
       "      <td>86441600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.093615</td>\n",
       "      <td>73449600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>128.779999</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>111598500.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>127.779999</td>\n",
       "      <td>128.710007</td>\n",
       "      <td>126.940002</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>90757300.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>128.660004</td>\n",
       "      <td>132.490005</td>\n",
       "      <td>128.550003</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>104319500.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>133.800003</td>\n",
       "      <td>139.669998</td>\n",
       "      <td>133.589996</td>\n",
       "      <td>136.869995</td>\n",
       "      <td>136.869995</td>\n",
       "      <td>120150900.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-22</th>\n",
       "      <td>136.279999</td>\n",
       "      <td>139.850006</td>\n",
       "      <td>135.020004</td>\n",
       "      <td>139.070007</td>\n",
       "      <td>139.070007</td>\n",
       "      <td>110666570.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10114 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "1980-12-12    0.128348    0.128906    0.128348    0.128348    0.101087   \n",
       "1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095813   \n",
       "1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088780   \n",
       "1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090978   \n",
       "1980-12-18    0.118862    0.119420    0.118862    0.118862    0.093615   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-01-15  128.779999  130.220001  127.000000  127.139999  127.139999   \n",
       "2021-01-19  127.779999  128.710007  126.940002  127.830002  127.830002   \n",
       "2021-01-20  128.660004  132.490005  128.550003  132.029999  132.029999   \n",
       "2021-01-21  133.800003  139.669998  133.589996  136.869995  136.869995   \n",
       "2021-01-22  136.279999  139.850006  135.020004  139.070007  139.070007   \n",
       "\n",
       "                 volume ticker  \n",
       "1980-12-12  469033600.0   AAPL  \n",
       "1980-12-15  175884800.0   AAPL  \n",
       "1980-12-16  105728000.0   AAPL  \n",
       "1980-12-17   86441600.0   AAPL  \n",
       "1980-12-18   73449600.0   AAPL  \n",
       "...                 ...    ...  \n",
       "2021-01-15  111598500.0   AAPL  \n",
       "2021-01-19   90757300.0   AAPL  \n",
       "2021-01-20  104319500.0   AAPL  \n",
       "2021-01-21  120150900.0   AAPL  \n",
       "2021-01-22  110666570.0   AAPL  \n",
       "\n",
       "[10114 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(\"AAPL\")[\"df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 50\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 30\n",
    "# scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "# Amazon stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "126/126 [==============================] - 42s 315ms/step - loss: 0.0017 - mean_absolute_error: 0.0235 - val_loss: 1.9334e-04 - val_mean_absolute_error: 0.0084\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00019, saving model to results/2021-01-22_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-30-layers-2-units-256.h5\n",
      "Epoch 2/5\n",
      "126/126 [==============================] - 46s 365ms/step - loss: 4.2205e-04 - mean_absolute_error: 0.0122 - val_loss: 2.6779e-04 - val_mean_absolute_error: 0.0111\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.00019\n",
      "Epoch 3/5\n",
      "126/126 [==============================] - 46s 363ms/step - loss: 3.3028e-04 - mean_absolute_error: 0.0115 - val_loss: 3.4872e-04 - val_mean_absolute_error: 0.0122\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.00019\n",
      "Epoch 4/5\n",
      "126/126 [==============================] - 46s 362ms/step - loss: 3.7896e-04 - mean_absolute_error: 0.0142 - val_loss: 2.4012e-04 - val_mean_absolute_error: 0.0127\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.00019\n",
      "Epoch 5/5\n",
      "126/126 [==============================] - 48s 383ms/step - loss: 3.5998e-04 - mean_absolute_error: 0.0141 - val_loss: 1.8122e-04 - val_mean_absolute_error: 0.0086\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00019 to 0.00018, saving model to results/2021-01-22_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-50-step-30-layers-2-units-256.h5\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_30</th>\n",
       "      <th>true_adjclose_30</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-03-03</th>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.092297</td>\n",
       "      <td>16172800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.239386</td>\n",
       "      <td>0.098010</td>\n",
       "      <td>-0.331683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-12</th>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.101004</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.079111</td>\n",
       "      <td>59248000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.257641</td>\n",
       "      <td>0.101966</td>\n",
       "      <td>-0.336753</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-13</th>\n",
       "      <td>0.099888</td>\n",
       "      <td>0.099888</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>0.078232</td>\n",
       "      <td>231302400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.285365</td>\n",
       "      <td>0.101087</td>\n",
       "      <td>-0.363597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-23</th>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.094055</td>\n",
       "      <td>22019200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.257634</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>-0.351688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-04-07</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>10684800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.243539</td>\n",
       "      <td>0.099768</td>\n",
       "      <td>-0.334078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>121.989998</td>\n",
       "      <td>116.050003</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>154515300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>119.657951</td>\n",
       "      <td>131.880005</td>\n",
       "      <td>3.337952</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>119.620003</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>118.570000</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>103162300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>121.777100</td>\n",
       "      <td>136.690002</td>\n",
       "      <td>2.567101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>118.610001</td>\n",
       "      <td>119.820000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.029999</td>\n",
       "      <td>118.029999</td>\n",
       "      <td>76322100.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>123.736969</td>\n",
       "      <td>129.410004</td>\n",
       "      <td>5.706970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>118.639999</td>\n",
       "      <td>118.769997</td>\n",
       "      <td>117.290001</td>\n",
       "      <td>117.339996</td>\n",
       "      <td>117.339996</td>\n",
       "      <td>73604300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>123.599564</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>6.259567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-24</th>\n",
       "      <td>113.910004</td>\n",
       "      <td>115.849998</td>\n",
       "      <td>112.589996</td>\n",
       "      <td>115.169998</td>\n",
       "      <td>115.169998</td>\n",
       "      <td>113874200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>122.252922</td>\n",
       "      <td>132.050003</td>\n",
       "      <td>7.082924</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2007 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "1981-03-03    0.117746    0.117746    0.117188    0.117188    0.092297   \n",
       "1981-03-12    0.100446    0.101004    0.100446    0.100446    0.079111   \n",
       "1981-03-13    0.099888    0.099888    0.099330    0.099330    0.078232   \n",
       "1981-03-23    0.119420    0.120536    0.119420    0.119420    0.094055   \n",
       "1981-04-07    0.115513    0.115513    0.114955    0.114955    0.090539   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
       "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
       "2020-11-18  118.610001  119.820000  118.000000  118.029999  118.029999   \n",
       "2020-11-20  118.639999  118.769997  117.290001  117.339996  117.339996   \n",
       "2020-11-24  113.910004  115.849998  112.589996  115.169998  115.169998   \n",
       "\n",
       "                 volume ticker  adjclose_30  true_adjclose_30  buy_profit  \\\n",
       "1981-03-03   16172800.0   AAPL    -0.239386          0.098010   -0.331683   \n",
       "1981-03-12   59248000.0   AAPL    -0.257641          0.101966   -0.336753   \n",
       "1981-03-13  231302400.0   AAPL    -0.285365          0.101087   -0.363597   \n",
       "1981-03-23   22019200.0   AAPL    -0.257634          0.098889   -0.351688   \n",
       "1981-04-07   10684800.0   AAPL    -0.243539          0.099768   -0.334078   \n",
       "...                 ...    ...          ...               ...         ...   \n",
       "2020-11-09  154515300.0   AAPL   119.657951        131.880005    3.337952   \n",
       "2020-11-12  103162300.0   AAPL   121.777100        136.690002    2.567101   \n",
       "2020-11-18   76322100.0   AAPL   123.736969        129.410004    5.706970   \n",
       "2020-11-20   73604300.0   AAPL   123.599564        126.599998    6.259567   \n",
       "2020-11-24  113874200.0   AAPL   122.252922        132.050003    7.082924   \n",
       "\n",
       "            sell_profit  \n",
       "1981-03-03          0.0  \n",
       "1981-03-12          0.0  \n",
       "1981-03-13          0.0  \n",
       "1981-03-23          0.0  \n",
       "1981-04-07          0.0  \n",
       "...                 ...  \n",
       "2020-11-09          0.0  \n",
       "2020-11-12          0.0  \n",
       "2020-11-18          0.0  \n",
       "2020-11-20          0.0  \n",
       "2020-11-24          0.0  \n",
       "\n",
       "[2007 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Mean calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_30</th>\n",
       "      <th>true_adjclose_30</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-03-03</th>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.092297</td>\n",
       "      <td>16172800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>1.003602</td>\n",
       "      <td>-0.091234</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-12</th>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.101004</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.100446</td>\n",
       "      <td>0.079111</td>\n",
       "      <td>59248000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>1.062293</td>\n",
       "      <td>-0.040834</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-13</th>\n",
       "      <td>0.099888</td>\n",
       "      <td>0.099888</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>0.099330</td>\n",
       "      <td>0.078232</td>\n",
       "      <td>231302400.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.345110</td>\n",
       "      <td>0.231067</td>\n",
       "      <td>-0.423343</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-23</th>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.094055</td>\n",
       "      <td>22019200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1.782974</td>\n",
       "      <td>2.658505</td>\n",
       "      <td>1.688920</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-04-07</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.090539</td>\n",
       "      <td>10684800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>31.401659</td>\n",
       "      <td>29.759630</td>\n",
       "      <td>31.311120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>120.500000</td>\n",
       "      <td>121.989998</td>\n",
       "      <td>116.050003</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>116.320000</td>\n",
       "      <td>154515300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.294073</td>\n",
       "      <td>0.119985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>116.614073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-12</th>\n",
       "      <td>119.620003</td>\n",
       "      <td>120.529999</td>\n",
       "      <td>118.570000</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>119.209999</td>\n",
       "      <td>103162300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.131274</td>\n",
       "      <td>0.151630</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>119.341273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-18</th>\n",
       "      <td>118.610001</td>\n",
       "      <td>119.820000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>118.029999</td>\n",
       "      <td>118.029999</td>\n",
       "      <td>76322100.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.035896</td>\n",
       "      <td>0.420100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.065894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>118.639999</td>\n",
       "      <td>118.769997</td>\n",
       "      <td>117.290001</td>\n",
       "      <td>117.339996</td>\n",
       "      <td>117.339996</td>\n",
       "      <td>73604300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.409586</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>117.749582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-24</th>\n",
       "      <td>113.910004</td>\n",
       "      <td>115.849998</td>\n",
       "      <td>112.589996</td>\n",
       "      <td>115.169998</td>\n",
       "      <td>115.169998</td>\n",
       "      <td>113874200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>-0.093119</td>\n",
       "      <td>0.276420</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>115.263117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2007 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "1981-03-03    0.117746    0.117746    0.117188    0.117188    0.092297   \n",
       "1981-03-12    0.100446    0.101004    0.100446    0.100446    0.079111   \n",
       "1981-03-13    0.099888    0.099888    0.099330    0.099330    0.078232   \n",
       "1981-03-23    0.119420    0.120536    0.119420    0.119420    0.094055   \n",
       "1981-04-07    0.115513    0.115513    0.114955    0.114955    0.090539   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
       "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
       "2020-11-18  118.610001  119.820000  118.000000  118.029999  118.029999   \n",
       "2020-11-20  118.639999  118.769997  117.290001  117.339996  117.339996   \n",
       "2020-11-24  113.910004  115.849998  112.589996  115.169998  115.169998   \n",
       "\n",
       "                 volume ticker  adjclose_30  true_adjclose_30  buy_profit  \\\n",
       "1981-03-03   16172800.0   AAPL     0.001062          1.003602   -0.091234   \n",
       "1981-03-12   59248000.0   AAPL     0.038277          1.062293   -0.040834   \n",
       "1981-03-13  231302400.0   AAPL    -0.345110          0.231067   -0.423343   \n",
       "1981-03-23   22019200.0   AAPL     1.782974          2.658505    1.688920   \n",
       "1981-04-07   10684800.0   AAPL    31.401659         29.759630   31.311120   \n",
       "...                 ...    ...          ...               ...         ...   \n",
       "2020-11-09  154515300.0   AAPL    -0.294073          0.119985    0.000000   \n",
       "2020-11-12  103162300.0   AAPL    -0.131274          0.151630    0.000000   \n",
       "2020-11-18   76322100.0   AAPL    -0.035896          0.420100    0.000000   \n",
       "2020-11-20   73604300.0   AAPL    -0.409586          0.117348    0.000000   \n",
       "2020-11-24  113874200.0   AAPL    -0.093119          0.276420    0.000000   \n",
       "\n",
       "            sell_profit  \n",
       "1981-03-03     0.000000  \n",
       "1981-03-12     0.000000  \n",
       "1981-03-13     0.000000  \n",
       "1981-03-23     0.000000  \n",
       "1981-04-07     0.000000  \n",
       "...                 ...  \n",
       "2020-11-09   116.614073  \n",
       "2020-11-12   119.341273  \n",
       "2020-11-18   118.065894  \n",
       "2020-11-20   117.749582  \n",
       "2020-11-24   115.263117  \n",
       "\n",
       "[2007 rows x 11 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.69794"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n",
    "future_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of Positive Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 30 days is 136.70$\n",
      "huber_loss loss: 0.00018122026813216507\n",
      "Mean Absolute Error: 1.2384207163951833\n",
      "Accuracy score: 0.8315894369706028\n",
      "Total buy profit: 15033.205924205773\n",
      "Total sell profit: 14727.665616894432\n",
      "Total profit: 29760.871541100205\n",
      "Profit per trade: 14.82853589491789\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2020-09-24  105.169998  110.250000  105.000000  108.220001  108.033615   \n",
      "2020-10-12  120.059998  125.180000  119.279999  124.400002  124.185753   \n",
      "2020-10-16  121.279999  121.550003  118.809998  119.019997  118.815010   \n",
      "2020-10-30  111.059998  111.989998  107.720001  108.860001  108.672516   \n",
      "2020-11-03  109.660004  111.489998  108.730003  110.440002  110.249794   \n",
      "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
      "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
      "2020-11-18  118.610001  119.820000  118.000000  118.029999  118.029999   \n",
      "2020-11-20  118.639999  118.769997  117.290001  117.339996  117.339996   \n",
      "2020-11-24  113.910004  115.849998  112.589996  115.169998  115.169998   \n",
      "\n",
      "                 volume ticker  adjclose_30  true_adjclose_30  buy_profit  \\\n",
      "2020-09-24  167743300.0   AAPL    -0.666890          0.357673         0.0   \n",
      "2020-10-12  240226800.0   AAPL     0.014565          0.375523         0.0   \n",
      "2020-10-16  115393800.0   AAPL    -0.328583          0.070321         0.0   \n",
      "2020-10-30  190272600.0   AAPL    20.683926         20.370062         0.0   \n",
      "2020-11-03  107624400.0   AAPL    -0.232076          0.177717         0.0   \n",
      "2020-11-09  154515300.0   AAPL    -0.294073          0.119985         0.0   \n",
      "2020-11-12  103162300.0   AAPL    -0.131274          0.151630         0.0   \n",
      "2020-11-18   76322100.0   AAPL    -0.035896          0.420100         0.0   \n",
      "2020-11-20   73604300.0   AAPL    -0.409586          0.117348         0.0   \n",
      "2020-11-24  113874200.0   AAPL    -0.093119          0.276420         0.0   \n",
      "\n",
      "            sell_profit  \n",
      "2020-09-24   108.700505  \n",
      "2020-10-12   124.171188  \n",
      "2020-10-16   119.143593  \n",
      "2020-10-30    87.988590  \n",
      "2020-11-03   110.481870  \n",
      "2020-11-09   116.614073  \n",
      "2020-11-12   119.341273  \n",
      "2020-11-18   118.065894  \n",
      "2020-11-20   117.749582  \n",
      "2020-11-24   115.263117  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

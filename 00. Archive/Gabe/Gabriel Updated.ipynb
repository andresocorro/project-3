{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Bidirectional\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yahoo_fin import stock_info as si\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting seed\n",
    "np.random.seed(314)\n",
    "tf.random.set_seed(314)\n",
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_in_unison(a, b):\n",
    "    # shuffle two arrays in the same way\n",
    "    state = np.random.get_state()\n",
    "    np.random.shuffle(a)\n",
    "    np.random.set_state(state)\n",
    "    np.random.shuffle(b)\n",
    "\n",
    "def load_data(ticker, n_steps=50, scale=True, shuffle=True, lookup_step=1, split_by_date=True,\n",
    "                test_size=0.2, feature_columns=['adjclose', 'volume', 'open', 'high', 'low']):\n",
    "\n",
    "    # see if ticker is already a loaded stock from yahoo finance\n",
    "    if isinstance(ticker, str):\n",
    "        # load it from yahoo_fin library\n",
    "        df = si.get_data(ticker)\n",
    "    elif isinstance(ticker, pd.DataFrame):\n",
    "        # already loaded, use it directly\n",
    "        df = ticker\n",
    "    else:\n",
    "        raise TypeError(\"ticker can be either a str or a `pd.DataFrame` instances\")\n",
    "    \n",
    "    # this will contain all the elements we want to return from this function\n",
    "    result = {}\n",
    "    # we will also return the original dataframe itself\n",
    "    result['df'] = df.copy()\n",
    "    # make sure that the passed feature_columns exist in the dataframe\n",
    "    for col in feature_columns:\n",
    "        assert col in df.columns, f\"'{col}' does not exist in the dataframe.\"\n",
    "    # add date as a column\n",
    "    if \"date\" not in df.columns:\n",
    "        df[\"date\"] = df.index\n",
    "    if scale:\n",
    "        column_scaler = {}\n",
    "        # scale the data (prices) from 0 to 1\n",
    "        for column in feature_columns:\n",
    "            scaler = preprocessing.MinMaxScaler()\n",
    "            df[column] = scaler.fit_transform(np.expand_dims(df[column].values, axis=1))\n",
    "            column_scaler[column] = scaler\n",
    "        # add the MinMaxScaler instances to the result returned\n",
    "        result[\"column_scaler\"] = column_scaler\n",
    "    # add the target column (label) by shifting by `lookup_step`\n",
    "    df['future'] = df['adjclose'].shift(-lookup_step)\n",
    "    # last `lookup_step` columns contains NaN in future column\n",
    "    # get them before droping NaNs\n",
    "    last_sequence = np.array(df[feature_columns].tail(lookup_step))\n",
    "    # drop NaNs\n",
    "    df.dropna(inplace=True)\n",
    "    sequence_data = []\n",
    "    sequences = deque(maxlen=n_steps)\n",
    "    for entry, target in zip(df[feature_columns + [\"date\"]].values, df['future'].values):\n",
    "        sequences.append(entry)\n",
    "        if len(sequences) == n_steps:\n",
    "            sequence_data.append([np.array(sequences), target])\n",
    "    # get the last sequence by appending the last `n_step` sequence with `lookup_step` sequence\n",
    "    # for instance, if n_steps=50 and lookup_step=10, last_sequence should be of 60 (that is 50+10) length\n",
    "    # this last_sequence will be used to predict future stock prices that are not available in the dataset\n",
    "    last_sequence = list([s[:len(feature_columns)] for s in sequences]) + list(last_sequence)\n",
    "    last_sequence = np.array(last_sequence).astype(np.float32)\n",
    "    # add to result\n",
    "    result['last_sequence'] = last_sequence\n",
    "    # construct the X's and y's\n",
    "    X, y = [], []\n",
    "    for seq, target in sequence_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "        # convert to numpy arrays\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    if split_by_date:\n",
    "        # split the dataset into training & testing sets by date (not randomly splitting)\n",
    "        train_samples = int((1 - test_size) * len(X))\n",
    "        result[\"X_train\"] = X[:train_samples]\n",
    "        result[\"y_train\"] = y[:train_samples]\n",
    "        result[\"X_test\"]  = X[train_samples:]\n",
    "        result[\"y_test\"]  = y[train_samples:]\n",
    "        if shuffle:\n",
    "            # shuffle the datasets for training (if shuffle parameter is set)\n",
    "            shuffle_in_unison(result[\"X_train\"], result[\"y_train\"])\n",
    "            shuffle_in_unison(result[\"X_test\"], result[\"y_test\"])\n",
    "    else:    \n",
    "        # split the dataset randomly\n",
    "        result[\"X_train\"], result[\"X_test\"], result[\"y_train\"], result[\"y_test\"] = train_test_split(X, y, \n",
    "                                                                                test_size=test_size, shuffle=shuffle)\n",
    "    # get the list of test set dates\n",
    "    dates = result[\"X_test\"][:, -1, -1]\n",
    "    # retrieve test features from the original dataframe\n",
    "    result[\"test_df\"] = result[\"df\"].loc[dates]\n",
    "    # remove duplicated dates in the testing dataframe\n",
    "    result[\"test_df\"] = result[\"test_df\"][~result[\"test_df\"].index.duplicated(keep='first')]\n",
    "        # remove dates from the training/testing sets & convert to float32\n",
    "    result[\"X_train\"] = result[\"X_train\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    result[\"X_test\"] = result[\"X_test\"][:, :, :len(feature_columns)].astype(np.float32)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1980-12-12</th>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.128348</td>\n",
       "      <td>0.101087</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-15</th>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.122210</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.121652</td>\n",
       "      <td>0.095813</td>\n",
       "      <td>175884800.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-16</th>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.113281</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.112723</td>\n",
       "      <td>0.088780</td>\n",
       "      <td>105728000.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-17</th>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.116071</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.115513</td>\n",
       "      <td>0.090978</td>\n",
       "      <td>86441600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980-12-18</th>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.119420</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.118862</td>\n",
       "      <td>0.093615</td>\n",
       "      <td>73449600.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-15</th>\n",
       "      <td>128.779999</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>111598500.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-19</th>\n",
       "      <td>127.779999</td>\n",
       "      <td>128.710007</td>\n",
       "      <td>126.940002</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>127.830002</td>\n",
       "      <td>90757300.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-20</th>\n",
       "      <td>128.660004</td>\n",
       "      <td>132.490005</td>\n",
       "      <td>128.550003</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>132.029999</td>\n",
       "      <td>104319500.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-21</th>\n",
       "      <td>133.800003</td>\n",
       "      <td>139.669998</td>\n",
       "      <td>133.589996</td>\n",
       "      <td>136.869995</td>\n",
       "      <td>136.869995</td>\n",
       "      <td>120150900.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-22</th>\n",
       "      <td>136.279999</td>\n",
       "      <td>139.850006</td>\n",
       "      <td>135.020004</td>\n",
       "      <td>139.070007</td>\n",
       "      <td>139.070007</td>\n",
       "      <td>110666570.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10114 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "1980-12-12    0.128348    0.128906    0.128348    0.128348    0.101087   \n",
       "1980-12-15    0.122210    0.122210    0.121652    0.121652    0.095813   \n",
       "1980-12-16    0.113281    0.113281    0.112723    0.112723    0.088780   \n",
       "1980-12-17    0.115513    0.116071    0.115513    0.115513    0.090978   \n",
       "1980-12-18    0.118862    0.119420    0.118862    0.118862    0.093615   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2021-01-15  128.779999  130.220001  127.000000  127.139999  127.139999   \n",
       "2021-01-19  127.779999  128.710007  126.940002  127.830002  127.830002   \n",
       "2021-01-20  128.660004  132.490005  128.550003  132.029999  132.029999   \n",
       "2021-01-21  133.800003  139.669998  133.589996  136.869995  136.869995   \n",
       "2021-01-22  136.279999  139.850006  135.020004  139.070007  139.070007   \n",
       "\n",
       "                 volume ticker  \n",
       "1980-12-12  469033600.0   AAPL  \n",
       "1980-12-15  175884800.0   AAPL  \n",
       "1980-12-16  105728000.0   AAPL  \n",
       "1980-12-17   86441600.0   AAPL  \n",
       "1980-12-18   73449600.0   AAPL  \n",
       "...                 ...    ...  \n",
       "2021-01-15  111598500.0   AAPL  \n",
       "2021-01-19   90757300.0   AAPL  \n",
       "2021-01-20  104319500.0   AAPL  \n",
       "2021-01-21  120150900.0   AAPL  \n",
       "2021-01-22  110666570.0   AAPL  \n",
       "\n",
       "[10114 rows x 7 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_data(\"AAPL\")[\"df\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(sequence_length, n_features, units=256, cell=LSTM, n_layers=2, dropout=0.3,\n",
    "                loss=\"mean_absolute_error\", optimizer=\"rmsprop\", bidirectional=False):\n",
    "    model = Sequential()\n",
    "    for i in range(n_layers):\n",
    "        if i == 0:\n",
    "            # first layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True), batch_input_shape=(None, sequence_length, n_features)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True, batch_input_shape=(None, sequence_length, n_features)))\n",
    "        elif i == n_layers - 1:\n",
    "            # last layer\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=False)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=False))\n",
    "        else:\n",
    "            # hidden layers\n",
    "            if bidirectional:\n",
    "                model.add(Bidirectional(cell(units, return_sequences=True)))\n",
    "            else:\n",
    "                model.add(cell(units, return_sequences=True))\n",
    "        # add dropout after each layer\n",
    "        model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation=\"linear\"))\n",
    "    model.compile(loss=loss, metrics=[\"mean_absolute_error\"], optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# Window size or the sequence length\n",
    "N_STEPS = 30\n",
    "# Lookup step, 1 is the next day\n",
    "LOOKUP_STEP = 1\n",
    "# scale feature columns & output price as well\n",
    "SCALE = True\n",
    "scale_str = f\"sc-{int(SCALE)}\"\n",
    "# shuffle the dataset\n",
    "SHUFFLE = True\n",
    "shuffle_str = f\"sh-{int(SHUFFLE)}\"\n",
    "# split the training/testing set by date\n",
    "SPLIT_BY_DATE = False\n",
    "split_by_date_str = f\"sbd-{int(SPLIT_BY_DATE)}\"\n",
    "# test ratio size, 0.2 is 20%\n",
    "TEST_SIZE = 0.2\n",
    "# features to use\n",
    "FEATURE_COLUMNS = [\"adjclose\", \"volume\", \"open\", \"high\", \"low\"]\n",
    "# date now\n",
    "date_now = time.strftime(\"%Y-%m-%d\")\n",
    "### model parameters\n",
    "N_LAYERS = 2\n",
    "# LSTM cell\n",
    "CELL = LSTM\n",
    "# 256 LSTM neurons\n",
    "UNITS = 256\n",
    "# 40% dropout\n",
    "DROPOUT = 0.4\n",
    "# bidirectional RNNs\n",
    "BIDIRECTIONAL = False\n",
    "### training parameters\n",
    "# mean absolute error loss\n",
    "# LOSS = \"mae\"\n",
    "# huber loss\n",
    "LOSS = \"huber_loss\"\n",
    "OPTIMIZER = \"adam\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "# Amazon stock market\n",
    "ticker = \"AAPL\"\n",
    "ticker_data_filename = os.path.join(\"data\", f\"{ticker}_{date_now}.csv\")\n",
    "# model name to save, making it as unique as possible based on parameters\n",
    "model_name = f\"{date_now}_{ticker}-{shuffle_str}-{scale_str}-{split_by_date_str}-\\\n",
    "{LOSS}-{OPTIMIZER}-{CELL.__name__}-seq-{N_STEPS}-step-{LOOKUP_STEP}-layers-{N_LAYERS}-units-{UNITS}\"\n",
    "if BIDIRECTIONAL:\n",
    "    model_name += \"-b\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they does not exist\n",
    "if not os.path.isdir(\"results\"):\n",
    "    os.mkdir(\"results\")\n",
    "if not os.path.isdir(\"logs\"):\n",
    "    os.mkdir(\"logs\")\n",
    "if not os.path.isdir(\"data\"):\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "127/127 [==============================] - 44s 324ms/step - loss: 6.9700e-04 - mean_absolute_error: 0.0172 - val_loss: 3.0164e-04 - val_mean_absolute_error: 0.0101\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.00030, saving model to results/2021-01-23_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-30-step-1-layers-2-units-256.h5\n",
      "Epoch 2/5\n",
      "127/127 [==============================] - 43s 337ms/step - loss: 3.0420e-04 - mean_absolute_error: 0.0119 - val_loss: 4.1232e-05 - val_mean_absolute_error: 0.0047\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.00030 to 0.00004, saving model to results/2021-01-23_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-30-step-1-layers-2-units-256.h5\n",
      "Epoch 3/5\n",
      "127/127 [==============================] - 44s 343ms/step - loss: 1.3958e-04 - mean_absolute_error: 0.0079 - val_loss: 2.5765e-05 - val_mean_absolute_error: 0.0048\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.00004 to 0.00003, saving model to results/2021-01-23_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-30-step-1-layers-2-units-256.h5\n",
      "Epoch 4/5\n",
      "127/127 [==============================] - 46s 361ms/step - loss: 1.4502e-04 - mean_absolute_error: 0.0083 - val_loss: 2.3395e-05 - val_mean_absolute_error: 0.0035\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.00003 to 0.00002, saving model to results/2021-01-23_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-30-step-1-layers-2-units-256.h5\n",
      "Epoch 5/5\n",
      "127/127 [==============================] - 43s 340ms/step - loss: 1.3101e-04 - mean_absolute_error: 0.0082 - val_loss: 1.5701e-05 - val_mean_absolute_error: 0.0027\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.00002 to 0.00002, saving model to results/2021-01-23_AAPL-sh-1-sc-1-sbd-0-huber_loss-adam-LSTM-seq-30-step-1-layers-2-units-256.h5\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "data = load_data(ticker, N_STEPS, scale=SCALE, split_by_date=SPLIT_BY_DATE, \n",
    "                shuffle=SHUFFLE, lookup_step=LOOKUP_STEP, test_size=TEST_SIZE, \n",
    "                feature_columns=FEATURE_COLUMNS)\n",
    "# save the dataframe\n",
    "data[\"df\"].to_csv(ticker_data_filename)\n",
    "# construct the model\n",
    "model = create_model(N_STEPS, len(FEATURE_COLUMNS), loss=LOSS, units=UNITS, cell=CELL, n_layers=N_LAYERS,\n",
    "                    dropout=DROPOUT, optimizer=OPTIMIZER, bidirectional=BIDIRECTIONAL)\n",
    "# some tensorflow callbacks\n",
    "checkpointer = ModelCheckpoint(os.path.join(\"results\", model_name + \".h5\"), save_weights_only=True, save_best_only=True, verbose=1)\n",
    "tensorboard = TensorBoard(log_dir=os.path.join(\"logs\", model_name))\n",
    "# train the model and save the weights whenever we see \n",
    "# a new optimal model using ModelCheckpoint\n",
    "history = model.fit(data[\"X_train\"], data[\"y_train\"],\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(data[\"X_test\"], data[\"y_test\"]),\n",
    "                    callbacks=[checkpointer, tensorboard],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir=\"logs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(test_df):\n",
    "    plt.plot(test_df[f'true_adjclose_{LOOKUP_STEP}'], c='b')\n",
    "    plt.plot(test_df[f'adjclose_{LOOKUP_STEP}'], c='r')\n",
    "    plt.xlabel(\"Days\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend([\"Actual Price\", \"Predicted Price\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_df(model, data):\n",
    "    # if predicted future price is higher than the current, \n",
    "    # then calculate the true future price minus the current price, to get the buy profit\n",
    "    buy_profit  = lambda current, true_future, pred_future: true_future - current if pred_future > current else 0\n",
    "    # if the predicted future price is lower than the current price,\n",
    "    # then subtract the true future price from the current price\n",
    "    sell_profit = lambda current, true_future, pred_future: current - true_future if pred_future < current else 0\n",
    "    X_test = data[\"X_test\"]\n",
    "    y_test = data[\"y_test\"]\n",
    "    # perform prediction and get prices\n",
    "    y_pred = model.predict(X_test)\n",
    "    if SCALE:\n",
    "        y_test = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(np.expand_dims(y_test, axis=0)))\n",
    "        y_pred = np.squeeze(data[\"column_scaler\"][\"adjclose\"].inverse_transform(y_pred))\n",
    "    test_df = data[\"test_df\"]\n",
    "    # add predicted future prices to the dataframe\n",
    "    test_df[f\"adjclose_{LOOKUP_STEP}\"] = y_pred\n",
    "    # add true future prices to the dataframe\n",
    "    test_df[f\"true_adjclose_{LOOKUP_STEP}\"] = y_test\n",
    "    # sort the dataframe by date\n",
    "    test_df.sort_index(inplace=True)\n",
    "    final_df = test_df\n",
    "    # add the buy profit column\n",
    "    final_df[\"buy_profit\"] = list(map(buy_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    # add the sell profit column\n",
    "    final_df[\"sell_profit\"] = list(map(sell_profit, \n",
    "                                    final_df[\"adjclose\"], \n",
    "                                    final_df[f\"adjclose_{LOOKUP_STEP}\"], \n",
    "                                    final_df[f\"true_adjclose_{LOOKUP_STEP}\"])\n",
    "                                    # since we don't have profit for last sequence, add 0's\n",
    "                                    )\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_1</th>\n",
       "      <th>true_adjclose_1</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-29</th>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>43904000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.225614</td>\n",
       "      <td>0.099329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.120572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05</th>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.100647</td>\n",
       "      <td>7929600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.210323</td>\n",
       "      <td>0.101087</td>\n",
       "      <td>0.109676</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-20</th>\n",
       "      <td>0.108817</td>\n",
       "      <td>0.108817</td>\n",
       "      <td>0.108259</td>\n",
       "      <td>0.108259</td>\n",
       "      <td>0.085264</td>\n",
       "      <td>24371200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.202689</td>\n",
       "      <td>0.086583</td>\n",
       "      <td>0.117425</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-24</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.106027</td>\n",
       "      <td>0.106027</td>\n",
       "      <td>0.083506</td>\n",
       "      <td>16979200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.199019</td>\n",
       "      <td>0.088780</td>\n",
       "      <td>0.115512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-03</th>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.092297</td>\n",
       "      <td>16172800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.202831</td>\n",
       "      <td>0.091418</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.110535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>121047300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>134.748123</td>\n",
       "      <td>133.720001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>127.720001</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>155088000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>134.232071</td>\n",
       "      <td>130.919998</td>\n",
       "      <td>7.632072</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>129.190002</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>100620900.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>132.687332</td>\n",
       "      <td>128.800003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.707336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>128.759995</td>\n",
       "      <td>131.449997</td>\n",
       "      <td>128.490005</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>88636800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>131.976273</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.086273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>130.800003</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>90221800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>131.904053</td>\n",
       "      <td>127.139999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.994049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "1981-01-29    0.133929    0.133929    0.133371    0.133371    0.105042   \n",
       "1981-02-05    0.127790    0.128906    0.127790    0.127790    0.100647   \n",
       "1981-02-20    0.108817    0.108817    0.108259    0.108259    0.085264   \n",
       "1981-02-24    0.107143    0.107143    0.106027    0.106027    0.083506   \n",
       "1981-03-03    0.117746    0.117746    0.117188    0.117188    0.092297   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-12-29  138.050003  138.789993  134.339996  134.869995  134.869995   \n",
       "2021-01-06  127.720001  131.050003  126.379997  126.599998  126.599998   \n",
       "2021-01-11  129.190002  130.169998  128.500000  128.979996  128.979996   \n",
       "2021-01-13  128.759995  131.449997  128.490005  130.889999  130.889999   \n",
       "2021-01-14  130.800003  131.000000  128.759995  128.910004  128.910004   \n",
       "\n",
       "                 volume ticker  adjclose_1  true_adjclose_1  buy_profit  \\\n",
       "1981-01-29   43904000.0   AAPL    0.225614         0.099329    0.000000   \n",
       "1981-02-05    7929600.0   AAPL    0.210323         0.101087    0.109676   \n",
       "1981-02-20   24371200.0   AAPL    0.202689         0.086583    0.117425   \n",
       "1981-02-24   16979200.0   AAPL    0.199019         0.088780    0.115512   \n",
       "1981-03-03   16172800.0   AAPL    0.202831         0.091418    0.000000   \n",
       "...                 ...    ...         ...              ...         ...   \n",
       "2020-12-29  121047300.0   AAPL  134.748123       133.720001    0.000000   \n",
       "2021-01-06  155088000.0   AAPL  134.232071       130.919998    7.632072   \n",
       "2021-01-11  100620900.0   AAPL  132.687332       128.800003    0.000000   \n",
       "2021-01-13   88636800.0   AAPL  131.976273       128.910004    0.000000   \n",
       "2021-01-14   90221800.0   AAPL  131.904053       127.139999    0.000000   \n",
       "\n",
       "            sell_profit  \n",
       "1981-01-29    -0.120572  \n",
       "1981-02-05     0.000000  \n",
       "1981-02-20     0.000000  \n",
       "1981-02-24     0.000000  \n",
       "1981-03-03    -0.110535  \n",
       "...                 ...  \n",
       "2020-12-29     0.121872  \n",
       "2021-01-06     0.000000  \n",
       "2021-01-11    -3.707336  \n",
       "2021-01-13    -1.086273  \n",
       "2021-01-14    -2.994049  \n",
       "\n",
       "[2017 rows x 11 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_final_df(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, data):\n",
    "    # retrieve the last sequence from data\n",
    "    last_sequence = data[\"last_sequence\"][-N_STEPS:]\n",
    "    # expand dimension\n",
    "    last_sequence = np.expand_dims(last_sequence, axis=0)\n",
    "    # get the prediction (scaled from 0 to 1)\n",
    "    prediction = model.predict(last_sequence)\n",
    "    # get the price (by inverting the scaling)\n",
    "    if SCALE:\n",
    "        predicted_price = data[\"column_scaler\"][\"adjclose\"].inverse_transform(prediction)[0][0]\n",
    "    else:\n",
    "        predicted_price = prediction[0][0]\n",
    "    return predicted_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load optimal model weights from results folder\n",
    "model_path = os.path.join(\"results\", model_name) + \".h5\"\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Mean calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "loss, mae = model.evaluate(data[\"X_test\"], data[\"y_test\"], verbose=0)\n",
    "# calculate the mean absolute error (inverse scaling)\n",
    "if SCALE:\n",
    "    mean_absolute_error = data[\"column_scaler\"][\"adjclose\"].inverse_transform([[mae]])[0][0]\n",
    "else:\n",
    "    mean_absolute_error = mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>volume</th>\n",
       "      <th>ticker</th>\n",
       "      <th>adjclose_1</th>\n",
       "      <th>true_adjclose_1</th>\n",
       "      <th>buy_profit</th>\n",
       "      <th>sell_profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1981-01-29</th>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.133929</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.133371</td>\n",
       "      <td>0.105042</td>\n",
       "      <td>43904000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.220176</td>\n",
       "      <td>0.150194</td>\n",
       "      <td>0.115134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-05</th>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.128906</td>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.127790</td>\n",
       "      <td>0.100647</td>\n",
       "      <td>7929600.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.260567</td>\n",
       "      <td>0.207479</td>\n",
       "      <td>0.159920</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-20</th>\n",
       "      <td>0.108817</td>\n",
       "      <td>0.108817</td>\n",
       "      <td>0.108259</td>\n",
       "      <td>0.108259</td>\n",
       "      <td>0.085264</td>\n",
       "      <td>24371200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.150544</td>\n",
       "      <td>0.052741</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-02-24</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.106027</td>\n",
       "      <td>0.106027</td>\n",
       "      <td>0.083506</td>\n",
       "      <td>16979200.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.302170</td>\n",
       "      <td>0.231375</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981-03-03</th>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117746</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.117188</td>\n",
       "      <td>0.092297</td>\n",
       "      <td>16172800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>5.079514</td>\n",
       "      <td>4.935595</td>\n",
       "      <td>4.987217</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>138.050003</td>\n",
       "      <td>138.789993</td>\n",
       "      <td>134.339996</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>134.869995</td>\n",
       "      <td>121047300.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2.094744</td>\n",
       "      <td>2.194830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.775251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>127.720001</td>\n",
       "      <td>131.050003</td>\n",
       "      <td>126.379997</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>126.599998</td>\n",
       "      <td>155088000.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2.485281</td>\n",
       "      <td>2.372598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.114717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>129.190002</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>128.500000</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>128.979996</td>\n",
       "      <td>100620900.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.195542</td>\n",
       "      <td>0.095813</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.784454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-13</th>\n",
       "      <td>128.759995</td>\n",
       "      <td>131.449997</td>\n",
       "      <td>128.490005</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>88636800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>22.565315</td>\n",
       "      <td>22.120768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>108.324684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-14</th>\n",
       "      <td>130.800003</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>128.759995</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>128.910004</td>\n",
       "      <td>90221800.0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.458149</td>\n",
       "      <td>0.301004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>128.451855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2017 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  open        high         low       close    adjclose  \\\n",
       "1981-01-29    0.133929    0.133929    0.133371    0.133371    0.105042   \n",
       "1981-02-05    0.127790    0.128906    0.127790    0.127790    0.100647   \n",
       "1981-02-20    0.108817    0.108817    0.108259    0.108259    0.085264   \n",
       "1981-02-24    0.107143    0.107143    0.106027    0.106027    0.083506   \n",
       "1981-03-03    0.117746    0.117746    0.117188    0.117188    0.092297   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-12-29  138.050003  138.789993  134.339996  134.869995  134.869995   \n",
       "2021-01-06  127.720001  131.050003  126.379997  126.599998  126.599998   \n",
       "2021-01-11  129.190002  130.169998  128.500000  128.979996  128.979996   \n",
       "2021-01-13  128.759995  131.449997  128.490005  130.889999  130.889999   \n",
       "2021-01-14  130.800003  131.000000  128.759995  128.910004  128.910004   \n",
       "\n",
       "                 volume ticker  adjclose_1  true_adjclose_1  buy_profit  \\\n",
       "1981-01-29   43904000.0   AAPL    0.220176         0.150194    0.115134   \n",
       "1981-02-05    7929600.0   AAPL    0.260567         0.207479    0.159920   \n",
       "1981-02-20   24371200.0   AAPL    0.150544         0.052741    0.000000   \n",
       "1981-02-24   16979200.0   AAPL    0.302170         0.231375    0.218664   \n",
       "1981-03-03   16172800.0   AAPL    5.079514         4.935595    4.987217   \n",
       "...                 ...    ...         ...              ...         ...   \n",
       "2020-12-29  121047300.0   AAPL    2.094744         2.194830    0.000000   \n",
       "2021-01-06  155088000.0   AAPL    2.485281         2.372598    0.000000   \n",
       "2021-01-11  100620900.0   AAPL    0.195542         0.095813    0.000000   \n",
       "2021-01-13   88636800.0   AAPL   22.565315        22.120768    0.000000   \n",
       "2021-01-14   90221800.0   AAPL    0.458149         0.301004    0.000000   \n",
       "\n",
       "            sell_profit  \n",
       "1981-01-29     0.000000  \n",
       "1981-02-05     0.000000  \n",
       "1981-02-20    -0.065280  \n",
       "1981-02-24     0.000000  \n",
       "1981-03-03     0.000000  \n",
       "...                 ...  \n",
       "2020-12-29   132.775251  \n",
       "2021-01-06   124.114717  \n",
       "2021-01-11   128.784454  \n",
       "2021-01-13   108.324684  \n",
       "2021-01-14   128.451855  \n",
       "\n",
       "[2017 rows x 11 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the final dataframe for the testing set\n",
    "final_df = get_final_df(model, data)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get future price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134.0836"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the future price\n",
    "future_price = predict(model, data)\n",
    "future_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of Positive Profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we calculate the accuracy by counting the number of positive profits\n",
    "accuracy_score = (len(final_df[final_df['sell_profit'] > 0]) + len(final_df[final_df['buy_profit'] > 0])) / len(final_df)\n",
    "# calculating total buy & sell profit\n",
    "total_buy_profit  = final_df[\"buy_profit\"].sum()\n",
    "total_sell_profit = final_df[\"sell_profit\"].sum()\n",
    "# total profit by adding sell & buy together\n",
    "total_profit = total_buy_profit + total_sell_profit\n",
    "# dividing total profit by number of testing samples (number of trades)\n",
    "profit_per_trade = total_profit / len(final_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Future price after 1 days is 134.08$\n",
      "huber_loss loss: 1.570141284901183e-05\n",
      "Mean Absolute Error: 0.41621362685500296\n",
      "Accuracy score: 0.9350520575111552\n",
      "Total buy profit: 16848.745068967342\n",
      "Total sell profit: 16440.671664070338\n",
      "Total profit: 33289.41673303768\n",
      "Profit per trade: 16.504420789805494\n"
     ]
    }
   ],
   "source": [
    "# printing metrics\n",
    "print(f\"Future price after {LOOKUP_STEP} days is {future_price:.2f}$\")\n",
    "print(f\"{LOSS} loss:\", loss)\n",
    "print(\"Mean Absolute Error:\", mean_absolute_error)\n",
    "print(\"Accuracy score:\", accuracy_score)\n",
    "print(\"Total buy profit:\", total_buy_profit)\n",
    "print(\"Total sell profit:\", total_sell_profit)\n",
    "print(\"Total profit:\", total_profit)\n",
    "print(\"Profit per trade:\", profit_per_trade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot actual prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot true/pred prices graph\n",
    "plot_graph(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  open        high         low       close    adjclose  \\\n",
      "2020-09-24  105.169998  110.250000  105.000000  108.220001  108.033615   \n",
      "2020-10-12  120.059998  125.180000  119.279999  124.400002  124.185753   \n",
      "2020-10-16  121.279999  121.550003  118.809998  119.019997  118.815010   \n",
      "2020-10-30  111.059998  111.989998  107.720001  108.860001  108.672516   \n",
      "2020-11-03  109.660004  111.489998  108.730003  110.440002  110.249794   \n",
      "2020-11-09  120.500000  121.989998  116.050003  116.320000  116.320000   \n",
      "2020-11-12  119.620003  120.529999  118.570000  119.209999  119.209999   \n",
      "2020-11-18  118.610001  119.820000  118.000000  118.029999  118.029999   \n",
      "2020-11-20  118.639999  118.769997  117.290001  117.339996  117.339996   \n",
      "2020-11-24  113.910004  115.849998  112.589996  115.169998  115.169998   \n",
      "\n",
      "                 volume ticker  adjclose_30  true_adjclose_30  buy_profit  \\\n",
      "2020-09-24  167743300.0   AAPL    -0.666890          0.357673         0.0   \n",
      "2020-10-12  240226800.0   AAPL     0.014565          0.375523         0.0   \n",
      "2020-10-16  115393800.0   AAPL    -0.328583          0.070321         0.0   \n",
      "2020-10-30  190272600.0   AAPL    20.683926         20.370062         0.0   \n",
      "2020-11-03  107624400.0   AAPL    -0.232076          0.177717         0.0   \n",
      "2020-11-09  154515300.0   AAPL    -0.294073          0.119985         0.0   \n",
      "2020-11-12  103162300.0   AAPL    -0.131274          0.151630         0.0   \n",
      "2020-11-18   76322100.0   AAPL    -0.035896          0.420100         0.0   \n",
      "2020-11-20   73604300.0   AAPL    -0.409586          0.117348         0.0   \n",
      "2020-11-24  113874200.0   AAPL    -0.093119          0.276420         0.0   \n",
      "\n",
      "            sell_profit  \n",
      "2020-09-24   108.700505  \n",
      "2020-10-12   124.171188  \n",
      "2020-10-16   119.143593  \n",
      "2020-10-30    87.988590  \n",
      "2020-11-03   110.481870  \n",
      "2020-11-09   116.614073  \n",
      "2020-11-12   119.341273  \n",
      "2020-11-18   118.065894  \n",
      "2020-11-20   117.749582  \n",
      "2020-11-24   115.263117  \n"
     ]
    }
   ],
   "source": [
    "print(final_df.tail(10))\n",
    "# save the final dataframe to csv-results folder\n",
    "csv_results_folder = \"csv-results\"\n",
    "if not os.path.isdir(csv_results_folder):\n",
    "    os.mkdir(csv_results_folder)\n",
    "csv_filename = os.path.join(csv_results_folder, model_name + \".csv\")\n",
    "final_df.to_csv(csv_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
